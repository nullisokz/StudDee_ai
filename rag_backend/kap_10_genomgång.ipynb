{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e725c060-4af6-42f1-94bb-0b02124f5941",
   "metadata": {},
   "source": [
    "# Chattbottar - Kapitel 10 \n",
    "\n",
    "I detta kodexempel ska vi få en grundläggande förståelse för hur chattbottar fungerar. Let's go! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d9446d-ed43-4c01-b2e6-3bb73affaf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install  google-genai\n",
    "# pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96af92f8-2199-4037-93f2-bdef2525eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from google import genai\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2555a65-c0af-4927-ac22-43cc9f58d4e9",
   "metadata": {},
   "source": [
    "# Använda en chattbott genom API\n",
    "Vi kommer nu demonstrera hur vi kan ha en egen chattbott genom att använda en API-nyckel från Google i detta fall. Andra alternativ är t.ex. ChatGPT/OpenAI. \n",
    "Om du i verkligheten ska arbeta med chattbottar kommer du mest sannolikt att använda färdiga API. \n",
    "\n",
    "För att skapa en API-nyckel behöver du gå in på följande hemsids: https://aistudio.google.com/ och sen gå till \"Create API key\". Notera, du behöver registrera ditt bankkort för att få en gratis provperiod. Annars funkar det inte. Som vanlig praxis inom systemutveckling så delar du inte din privata API-nyckel eftersom då kan andra använda den vilket kostar pengar. Man kan använda \"api_key = api_key=os.getenv(\"API_KEY\")\" för detta ändamål. I koden nedan **skriver jag explicit ut min API-nyckel som du dock inte kommer kuna använda (du behöver skapa en egen)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f1ffd-c832-4fd2-89f3-85bb958f75b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Här är fem kännetecken för en skicklig programmerare:\n",
      "\n",
      "1. En skicklig programmerare har en stark logisk förmåga och kan effektivt bryta ner komplexa problem i mindre, hanterbara delar.\n",
      "2. De skriver läsbar och välstrukturerad kod som inte bara löser uppgiften, utan även är enkel för andra att förstå och underhålla.\n",
      "3. Genom en ständig nyfikenhet och vilja att lära sig nya tekniker håller de sig uppdaterade i en bransch som är i ständig förändring.\n",
      "4. De besitter ett stort tålamod vid felsökning och strävar efter att förstå grundorsaken till problem snarare än att bara applicera tillfälliga lösningar.\n",
      "5. Slutligen är god kommunikationsförmåga och ödmjukhet inför andras idéer avgörande, eftersom framgångsrik mjukvaruutveckling oftast bygger på ett bra lagarbete.\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# api_key = api_key=os.getenv(\"API_KEY\")\n",
    "\n",
    "api_key = 'HEMLIGT'\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-3-flash-preview\", \n",
    "    contents=\"Skriv i 5 meningar vad som kännetecknar en skicklig programmerare.\"\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cdd7aa-1866-4107-a502-156f152cbfc5",
   "metadata": {},
   "source": [
    "# Skapa en mycket enkel applikation\n",
    "Vi kan också skapa en enkel applikation. Men lite kreativitet så inser man att det finns många möjligheter att bygga/utveckla sådant man är intresserad av."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed5d2d8a-4373-4d58-bdff-8c2158745cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Gemini chat ***\n",
      "Type <q> to exit chat.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini: None\n",
      "Gemini: Hej! Vad kan jag hjälpa dig med idag?\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Gemini chat ***\")\n",
    "print(\"Type <q> to exit chat.\")\n",
    "\n",
    "while True:\n",
    "    prompt = input(\"User: \")\n",
    "    if prompt == \"q\":\n",
    "        break\n",
    "    else:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-3-flash-preview\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        print(\"Gemini:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75abe017-f8a7-4244-b99f-cb0f7ddfcfc1",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ed0f7-7d1c-466a-a23d-341f17661949",
   "metadata": {},
   "source": [
    "## Läsa in PDF-fil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddd0aa4-549d-4e90-b6a9-e936c185a3df",
   "metadata": {},
   "source": [
    "Vi börjar med att läsa in en PDF-fil som chattbotten kommer ge svar utifrån. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64f7836c-9675-4aae-8e45-70bb7c37e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"chattbot.pdf\")\n",
    "\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc92a8d5-92b6-4b54-b03f-56ee19e358e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23416\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26511ad6-f832-465f-bb83-3d223bf86541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kapitel 1\n",
      "Chattbot\n",
      "1.1 Chattbottar\n",
      "I detta kapitel kommer vi lära oss mer om hur chattbottar såsom ChatGPT fungerar och\n",
      "hur man ställer effektiva frågor till dem, vilket kallas prompt engineering . Vi kommer\n",
      "därefter lära oss hur vi bygger en lokal chattbot som vi kan använda på vår egna dator.\n",
      "Kapitlet avslutas med att gå igenom RAG vilket låter oss anpassa chattbottens svar\n",
      "utifrån en given kontext, exempelvis utifrån egna dokument.\n",
      "1.1.1 ChatGPT och prompt engineering\n",
      "Chattbottar, som till exempel ChatGPT, används av många m\n"
     ]
    }
   ],
   "source": [
    "print(text[17:550])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd44ee3-1f37-49fd-89cd-15d8cfe53008",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea598391-db66-47e1-9906-657a2b43b920",
   "metadata": {},
   "source": [
    "### Fixed length-chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "141465a2-4992-4a3d-a312-b1994623820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antal chunks: 30.\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "n = 1000\n",
    "overlap = 200\n",
    "for i in range(0, len(text), n - overlap):\n",
    "    chunks.append(text[i:i + n])\n",
    "\n",
    "print(f\"Antal chunks: {len(chunks)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f1d1208-8c68-48b2-a938-8d6c7f7f70da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chattbot med RAG2Kapitel 1\n",
      "Chattbot\n",
      "1.1 Chattbottar\n",
      "I detta kapitel kommer vi lära oss mer om hur chattbottar såsom ChatGPT fungerar och\n",
      "hur man ställer effektiva frågor till dem, vilket kallas prompt engineering . Vi kommer\n",
      "därefter lära oss hur vi bygger en lokal chattbot som vi kan använda på vår egna dator.\n",
      "Kapitlet avslutas med att gå igenom RAG vilket låter oss anpassa chattbottens svar\n",
      "utifrån en given kontext, exempelvis utifrån egna dokument.\n",
      "1.1.1 ChatGPT och prompt engineering\n",
      "Chattbottar, som till exempel ChatGPT, används av många människor för en rad olika\n",
      "syften. Alltifrån att skapa kreativt innehåll, få förslag på förbättringar av skriven text\n",
      "eller programmeringskod till att lösa mer komplexa problem.\n",
      "I korthet har chattbottar tränats på enorma datamängder och har från detta lärt sig vad\n",
      "som är rimliga sekvenser av ord. Exempelvis vet vi att om någon säger “Hej, hur mår\n",
      "___” så brukar det sista ordet vara “du” för att meningen ska bli “Hej, hur mår du” .\n",
      "När vi ställer \n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0268d77-6602-4457-ac6e-f7e209c02b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chattbot\n",
      "1.1 Chattbottar\n",
      "I detta kapitel kommer vi lära oss mer om hur chattbottar såsom ChatGPT fungerar och\n",
      "hur man ställer effektiva frågor till dem, vilket kallas prompt engineering . Vi kommer\n",
      "därefter lära oss hur vi bygger en lokal chattbot som vi kan använda på vår egna dator.\n",
      "Kapitlet avslutas med att gå igenom RAG vilket låter oss anpassa chattbottens svar\n",
      "utifrån en given kontext, exempelvis utifrån egna dokument.\n",
      "1.1.1 ChatGPT och prompt engineering\n",
      "Chattbottar, som till exempel ChatGPT, används av många människor för en rad olika\n",
      "syften. \n"
     ]
    }
   ],
   "source": [
    "print(text[26:584])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a06000c-d0d4-45f0-a674-715a616ca36c",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "Se t.ex. s.321 i kursboken \"Lär dig AI från grunden - Tillämpad maskininlärning med Python\" för vad Embeddings innebär. I korthet, ord representeras med vektorer/siffror. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e52e145a-8684-4aa6-a192-7e98b1d18ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "def create_embeddings(text, model=\"text-embedding-004\", task_type=\"SEMANTIC_SIMILARITY\"): \n",
    "    return client.models.embed_content(model=model, contents=text, config=types.EmbedContentConfig(task_type=task_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d25a867-4b3a-479a-a490-f6723bbc4ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = create_embeddings(chunks)\n",
    "len(embeddings.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b824e558-81ba-4065-83b1-60b2fe6d683f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.057309315,\n",
       " -0.010547505,\n",
       " -0.08322796,\n",
       " 0.024299115,\n",
       " 0.055630915,\n",
       " 0.048652556,\n",
       " 0.049652215,\n",
       " -0.027345037,\n",
       " 0.044459436,\n",
       " -0.042770572]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embeddings)\n",
    "\n",
    "embeddings.embeddings[0].values[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0414a050-0e5f-4d51-8322-fe8e225aca50",
   "metadata": {},
   "source": [
    "## Semantisk sökning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e252a24b-c86b-4152-8045-7b7dc5a692ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    return (np.dot(vec1, vec2) / (np.linalg.norm(vec1)*np.linalg.norm(vec2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f99cc00-f005-41dc-9df8-cd0054734a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, chunks, embeddings, k=5):\n",
    "    query_embedding = create_embeddings(query).embeddings[0].values \n",
    "    similarity_scores = []\n",
    "    \n",
    "    for i, chunk_embedding in enumerate(embeddings.embeddings):\n",
    "        similarity_score = cosine_similarity(query_embedding, chunk_embedding.values)\n",
    "        similarity_scores.append((i, similarity_score))\n",
    "\n",
    "    similarity_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [index for index, _ in similarity_scores[:k]]\n",
    "    \n",
    "    return [chunks[index] for index in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bbb0be9-e15c-46de-9c2d-3b32c94e392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i ger\\nmodellen en kontext, ofta ett eller flera dokument eller liknande, att förhålla sig till.\\nI en prompt säger vi åt modellen att enbart svara utifrån den givna kontexten. Om\\nmodellen inte hittar svaret i kontexten ska den säga det istället för att försöka hitta\\nsvaren någon annanstans eller gissa.\\n7En RAG-modell innehåller alltså två delar.\\nDen första delen är en retriever, som söker efter relevanta stycken i en större text.\\nDessa stycken skickas sedan vidare som kontext till den andra delen, en generator som\\ngenererar svaren utifrån den givna kontexten.\\nFör att ge modellen en kontext behöver vi läsa in data (exempelvis ett eller flera PDF-\\ndokument) och bearbeta den så att vi kan göra en semantisk sökning i datan, det vill\\nsäga leta upp de stycken i kontexten som verkar ha mest med själva frågan att göra.\\nDessa stycken skickar vi sedan med till språkmodellen när vi ställer vår fråga.\\nDet finns ett antal ramverk för att implementera RAG, bland annat LangChain. Vi\\nkommer inte använd']\n"
     ]
    }
   ],
   "source": [
    "fråga = \"Vad kan RAG användas till?\"\n",
    "svar = semantic_search(fråga, chunks=chunks, embeddings=embeddings, k=1)\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c860ec-2f8c-4a51-8472-f1726ad57ccf",
   "metadata": {},
   "source": [
    "## Generera bra svar med RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7073be44-fe23-4420-a339-7e42a1781d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Jag kommer ställa dig en fråga, och jag vill att du svarar\n",
    "baserat bara på kontexten jag skickar med, och ingen annan information.\n",
    "Om det inte finns nog med information i kontexten för att svara på frågan,\n",
    "säg \"Det vet jag inte\". Försök inte att gissa.\n",
    "Formulera dig enkelt och dela upp svaret i fina stycken. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f5699b1-5a6c-4811-a0ec-dd1ab5342f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_prompt(query):\n",
    "    context = \"\\n\".join(semantic_search(query, chunks, embeddings))\n",
    "    user_prompt = f\"Frågan är {query}. Här är kontexten: {context}.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24a7b5a6-d8e8-4692-87c7-fd49fac36061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(system_prompt, user_message, model=\"gemini-3-flash-preview\"):\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        config=genai.types.GenerateContentConfig(\n",
    "            system_instruction=system_prompt),\n",
    "            contents=generate_user_prompt(user_message)\n",
    "        )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166eed64-fbef-4d57-adad-8df1cccab7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "555d729f-44bb-4e62-8949-5344c72c44b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En RAG-modell är ett system där man ger en språkmodell en specifik kontext, till exempel ett eller flera dokument, som den ska förhålla sig till när den svarar på frågor. Syftet är att modellen ska svara enbart utifrån den givna informationen istället för att gissa eller hämta svar från andra källor.\n",
      "\n",
      "Modellen består av två huvuddelar: en **retriever** och en **generator**. Retrieverns uppgift är att söka igenom en större mängd data och leta upp de stycken som är mest relevanta för frågan som ställts. Detta görs ofta genom en så kallad semantisk sökning.\n",
      "\n",
      "De relevanta styckena skickas sedan vidare till generatorn. Generatorn skapar därefter ett svar baserat på den utvalda kontexten. RAG-tekniken kan användas med många olika typer av data, exempelvis text från PDF-dokument.\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(system_prompt, \"Vad är RAG?\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9c38332-cd4a-4838-8270-b1253d05046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det vet jag inte.\n"
     ]
    }
   ],
   "source": [
    "fråga = \"Vad är meningen med livet?\"\n",
    "svar = generate_response(system_prompt, fråga).text\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c5485b9-44d8-4639-9215-eb60393a0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering handlar om hur man ställer effektiva frågor till chattbottar, såsom ChatGPT. Syftet med detta är att få \"bättre\" och mer användbara svar från språkmodellen.\n",
      "\n",
      "Rent praktiskt går det ut på att man som användare är så specifik, beskrivande och detaljerad som möjligt. Man kan till exempel ge information om önskad kontext, stil, format och längd på svaret för att styra chattbotten rätt.\n"
     ]
    }
   ],
   "source": [
    "fråga = \"Vad är prompt engineering?\"\n",
    "svar = generate_response(system_prompt, fråga).text\n",
    "print(svar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f643f7-92d1-49b2-bb5a-546098474dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8aaf2a8-418f-45e8-9c6b-5d43ee71b53c",
   "metadata": {},
   "source": [
    "# Evaluering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cffc8c93-efc5-4ffe-9239-2f98dd210aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilka delar utgör en RAG-modell?\n",
      "\n",
      "En RAG-modell innehåller två delar: \n",
      "en retriever som söker efter relevanta stycken i en text, \n",
      "och en generator som genererar svar utifrån den givna kontexten.\n"
     ]
    }
   ],
   "source": [
    "validation_data = [\n",
    "{\"question\": \"Vilka delar utgör en RAG-modell?\",\n",
    "\"ideal_answer\": \"\"\"En RAG-modell innehåller två delar: \n",
    "en retriever som söker efter relevanta stycken i en text, \n",
    "och en generator som genererar svar utifrån den givna kontexten.\"\"\"}\n",
    "]\n",
    "\n",
    "print(validation_data[0][\"question\"])\n",
    "print()\n",
    "print(validation_data[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280210b-11c3-4420-8641-652343e25ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9443d6e1-dc9f-41b2-924e-f28a2226bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_system_prompt = \"\"\"Du är ett intelligent utvärderingssystem vars uppgift är att utvärdera en AI-assistents svar. \n",
    "Om svaret är väldigt nära det önskade svaret, sätt poängen 1. Om svaret är felaktigt eller inte bra nog, sätt poängen 0.\n",
    "Om svaret är delvis i linje med det önskade svaret, sätt poängen 0.5. Motivera kort varför du sätter den poäng du gör.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55e42632-b16f-477a-a84a-e8b4816a4d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poäng: 1\n",
      "\n",
      "Motivering: AI-assistentens svar är korrekt och innehåller precis de två delar som efterfrågas (retriever och generator) med förklaringar som stämmer väl överens med det önskade svaret.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "\n",
    "evaluation_prompt = f\"\"\"Fråga: {query}\n",
    "AI-assistentens svar: {response.text}\n",
    "Önskat svar: {validation_data[0]['ideal_answer']}\"\"\"\n",
    "\n",
    "# Note, we have created a \"evaluation_system_prompt\" and a \"evaluation_prompt\" that we use in our function \"generate_response\" that we created before. \n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt)\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4392962-0b5f-4b60-a5ed-18a30cf93b09",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c826583-997a-4c5b-8b8f-233e2f123994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vilket programmeringsspråk är kapitlet skrivet i?\n",
      "Python\n"
     ]
    }
   ],
   "source": [
    "# Try change to \"ideal_answer\": \"Java\" and notice that if the user defines the wrong \"ideal answer\", then it gets weird. \n",
    "# In a wider context, how do you define ideal answers to questions that have no exact answer and who does this? \n",
    "\n",
    "validation_data_2 = [\n",
    "{\"question\": \"Vilket programmeringsspråk är kapitlet skrivet i?\",\n",
    "\"ideal_answer\": \"Python\"}\n",
    "]\n",
    "print(validation_data_2[0][\"question\"])\n",
    "print(validation_data_2[0][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4d6055f-2009-46e2-8039-d94e71eb3747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Programmeringsspråket som kapitlet använder är Python.\n",
      "\n",
      "Detta framgår då texten nämner att de kommer att använda sig av vanliga Python-bibliotek som \"pypdf\" för att läsa in text och \"numpy\" för beräkningar. \n",
      "\n",
      "Även kodexemplen i texten, som till exempel `from pypdf import PdfRead`, är skrivna i Python.\n"
     ]
    }
   ],
   "source": [
    "query = validation_data_2[0][\"question\"]\n",
    "\n",
    "response = generate_response(system_prompt, query)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8d10d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Det vet jag inte.\n"
     ]
    }
   ],
   "source": [
    "query5 = \"Vad är hamburgare för något?\"\n",
    "\n",
    "response = generate_response(system_prompt,query5)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9d8c553-7230-4456-baef-2ef2255df433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poäng: 1\n",
      "\n",
      "Motivering: Svaret är korrekt och välmotiverat utifrån den givna kontexten.\n"
     ]
    }
   ],
   "source": [
    "evaluation_prompt = f\"\"\"Fråga: {query}\n",
    "AI-assistentens svar: {response.text}\n",
    "Önskat svar: {validation_data_2[0]['ideal_answer']}\"\"\"\n",
    "\n",
    "evaluation_response = generate_response(evaluation_system_prompt, evaluation_prompt)\n",
    "print(evaluation_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a62463f-4ae4-4ad0-acc8-ce11f85a4ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5086c60a-10bc-47cc-8754-4c548cb864c4",
   "metadata": {},
   "source": [
    "# Fördjupning\n",
    "Den som är intresserad av att arbeta med chattbottar för t.ex. del 2 av kunskapskontrollen kan fördjupa sig inom LangChain, se t.ex. här: \n",
    "https://academy.langchain.com/collections/foundation\n",
    "\n",
    "Vill man få en snabb överblick, se t.ex. \"Quickstart LangChain Essentials - Python\" här: https://academy.langchain.com/collections/quickstart\n",
    "\n",
    "Vill man få en överblick över LangChain, LangGraph och LangSmith, se här: https://www.youtube.com/watch?v=vJOGC8QJZJQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64949f44-e5b7-4424-93f2-b799b14237f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
